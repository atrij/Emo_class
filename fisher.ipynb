{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labeled_data(path_data,path_image):\n",
    "    subject=os.listdir(path_data)\n",
    "    labeled_data=[]\n",
    "    for i in range(0,len(subject)):\n",
    "        \n",
    "        path_subject=path_data+'/'+subject[i]\n",
    "    \n",
    "        subject_sequence= os.listdir(path_subject)\n",
    "   \n",
    "        for j in range(0,len(subject_sequence)):\n",
    "            path_sequence=path_subject+'/'+subject_sequence[j]\n",
    "            emotion=os.listdir(path_sequence)\n",
    "            if len(emotion)==0:\n",
    "                continue\n",
    "            f = open(path_sequence+'/'+emotion[0], 'r')\n",
    "            emo_tag=f.readlines()\n",
    "            emo=int(float(emo_tag[0]))\n",
    "            image_name = emotion[0][0:-12]\n",
    "            image_path = path_image+'/'+subject[i]+'/'+subject_sequence[j]+'/'+image_name+'.png'\n",
    "            image_tuple=(image_path,emo)\n",
    "            labeled_data.append(image_tuple)\n",
    "    return labeled_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_desc_sift(img_path):\n",
    "    face_cord=image_pre_harr(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    if len(face_cord) == 0 :\n",
    "        return []\n",
    "    (x,y,w,h) = face_cord[0]\n",
    "    img=img[y:y+h, x:x+w]\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray,None)\n",
    "    #print 'image:',img_path,'# descriptors:',des.shape\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_pre_harr(img_path):\n",
    "    face_cascade = cv2.CascadeClassifier('/home/atrij/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decs_dataset(labeled_data):\n",
    "    des=[]\n",
    "    Y=[]\n",
    "    print 'computing descriptors:', len(labeled_data)\n",
    "    for data in labeled_data:\n",
    "        #print 'image number',i\n",
    "        #print data[0]\n",
    "        des_img=img_desc_sift(data[0])\n",
    "        if len(des_img)==0:\n",
    "            continue\n",
    "        des.append(des_img)\n",
    "        label=data[1]\n",
    "        Y.append(label)\n",
    "    #des_stack_train=[desc for img in des_train for desc in img]\n",
    "    return des,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_descriptor_label(filename_des,filename_label,labeled_data):\n",
    "    if os.path.exists(filename_des) & os.path.exists(filename_label):\n",
    "        return\n",
    "    else:\n",
    "        des,y=decs_dataset(labeled_data)\n",
    "        fileObject = open(filename_des,'wb')\n",
    "        pickle.dump(des,fileObject)\n",
    "        fileObject.close()\n",
    "        fileObject1 = open(filename_label,'wb')\n",
    "        pickle.dump(y,fileObject1)\n",
    "        fileObject1.close()\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data=\"/home/atrij/artificial_intelligence/CK+/Emotion\"\n",
    "path_image=\"/home/atrij/artificial_intelligence/CK+/cohn-kanade-images\"\n",
    "\n",
    "ld= labeled_data(path_data,path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_des='img_des'\n",
    "filename_label='img_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_val_split_idxs(total_rows, percent_test, percent_val):\n",
    "    \"\"\"\n",
    "    Get indexes for training, test, and validation rows, given a total number of rows.\n",
    "    Assumes indexes are sequential integers starting at 0: eg [0,1,2,3,...N]\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    training_idxs, test_idxs, val_idxs\n",
    "        Both lists of integers\n",
    "    \"\"\"\n",
    "    if percent_test + percent_val >= 1.0:\n",
    "        raise ValueError('percent_test and percent_val must sum to less than 1.0')\n",
    "\n",
    "    row_range = range(total_rows)\n",
    "\n",
    "    no_test_rows = int(total_rows*(percent_test))\n",
    "    test_idxs = np.random.choice(row_range, size=no_test_rows, replace=False)\n",
    "    # remove test indexes\n",
    "    row_range = [idx for idx in row_range if idx not in test_idxs]\n",
    "\n",
    "    no_val_rows = int(total_rows*(percent_val))\n",
    "    val_idxs = np.random.choice(row_range, size=no_val_rows, replace=False)\n",
    "    # remove validation indexes\n",
    "    training_idxs = [idx for idx in row_range if idx not in val_idxs]\n",
    "\n",
    "    #print 'Train-test-val split: %i training rows, %i test rows, %i validation rows' % (len(training_idxs), len(test_idxs), len(val_idxs))\n",
    "\n",
    "    return training_idxs, test_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_features(img_descs,cluster_model):\n",
    "    \"\"\"\n",
    "    Cluster the training features using the cluster_model\n",
    "    and convert each set of descriptors in img_descs\n",
    "    to a Visual Bag of Words histogram.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : list of lists of SIFT descriptors (img_descs)\n",
    "\n",
    "    training_idxs : array/list of integers\n",
    "        Indicies for the training rows in img_descs\n",
    "\n",
    "    cluster_model : clustering model (eg KMeans from scikit-learn)\n",
    "        The model used to cluster the SIFT features\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    cluster_model :\n",
    "    cluster_model has been fit to the training set\n",
    "    \"\"\"\n",
    "    n_clusters = cluster_model.n_clusters\n",
    "    des_stack_train=[desc for img in img_descs for desc in img]\n",
    "    all_train_descriptors = np.array(des_stack_train)\n",
    "\n",
    "    if all_train_descriptors.shape[1] != 128:\n",
    "        raise ValueError('Expected SIFT descriptors to have 128 features, got', all_train_descriptors.shape[1])\n",
    "\n",
    "    print '%i descriptors before clustering' % all_train_descriptors.shape[0]\n",
    "\n",
    "    # Cluster descriptors to get codebook\n",
    "    print 'Using clustering model %s...' % repr(cluster_model)\n",
    "    print 'Clustering on training set to get codebook of %i words' % n_clusters\n",
    "\n",
    "    # train kmeans or other cluster model on those descriptors selected above\n",
    "    cluster_model.fit(all_train_descriptors)\n",
    "    print 'done clustering.'\n",
    "\n",
    "    return cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram(cluster_model,des,K):\n",
    "    words=cluster_model.predict(des)\n",
    "    img_bow_hist = np.array([np.bincount(words, minlength=K)])\n",
    "    return img_bow_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cluster_split(des,Y, K, percent_test, percent_val):\n",
    "    emo1=[]\n",
    "    emo2=[]\n",
    "    emo3=[]\n",
    "    emo4=[]\n",
    "    emo5=[]\n",
    "    emo6=[]\n",
    "    emo7=[]\n",
    "    emotions=[1,2,3,4,5,6,7]\n",
    "    \n",
    "    print '\\n total size of data:',len(des)\n",
    "    \n",
    "    # segregating database images based on emotion label\n",
    "    for i,label in enumerate(Y):\n",
    "        emo= str(label)\n",
    "        a='emo'+emo\n",
    "        des_label=[des_keypoint for des_keypoint in des[i]]\n",
    "        locals()[a].append(des_label)\n",
    "        \n",
    "    #splitting data into test, train and validation such that every label is split equally\n",
    "    train=[]\n",
    "    Y_train=[]\n",
    "    test=[]\n",
    "    Y_test=[]\n",
    "    validation=[]\n",
    "    Y_val=[]\n",
    "    for emo in emotions:\n",
    "        total_rows=len(locals()['emo'+str(emo)])\n",
    "        training_idxs, test_idxs, val_idxs = train_test_val_split_idxs(total_rows,percent_test,percent_val)\n",
    "        train_emo=[locals()['emo'+str(emo)][i] for i in training_idxs]\n",
    "        test_emo=[locals()['emo'+str(emo)][i] for i in test_idxs]\n",
    "        val_emo=[locals()['emo'+str(emo)][i] for i in val_idxs]\n",
    "        train_emo_label=[locals()['emo'+str(emo)][i] for i in training_idxs]\n",
    "        test_emo=[locals()['emo'+str(emo)][i] for i in test_idxs]\n",
    "        val_emo=[locals()['emo'+str(emo)][i] for i in val_idxs]\n",
    "        for rows in train_emo:\n",
    "            train.append(rows)\n",
    "            Y_train.append(emo)\n",
    "        for rows in test_emo:\n",
    "            test.append(rows)\n",
    "            Y_test.append(emo)\n",
    "        for rows in val_emo:\n",
    "            validation.append(rows)\n",
    "            Y_val.append(emo)\n",
    "    print '\\n size of training data:',len(train),'\\n size of validation data:',len(validation),'\\n size of test data:',len(test)\n",
    "    cluster_model = cluster_features(train,cluster_model=MiniBatchKMeans(n_clusters=K))\n",
    "    \n",
    "  \n",
    "    print '\\n calculting histogram vectors of training set'\n",
    "    X_train=[]\n",
    "    for des_img in train:\n",
    "        hist=histogram(cluster_model,des_img,K)\n",
    "        X_train.append(hist)\n",
    "    X_train=np.array(X_train)\n",
    "    X_train=X_train.reshape(len(X_train),K)\n",
    "    \n",
    "    # building validation set in terms of labels and vectors\n",
    "    X_val=[]\n",
    "    print '\\n calculting histogram vectors of validation set'\n",
    "    for des_img in validation:\n",
    "        hist=histogram(cluster_model,des_img,K)\n",
    "        X_val.append(hist)\n",
    "    X_val=np.array(X_val)\n",
    "    X_val=X_val.reshape(len(X_val),K)\n",
    "    \n",
    "    # building test set in terms of labels and vectors\n",
    "    X_test=[]\n",
    "    print '\\n calculting histogram vectors of test set'\n",
    "    for des_img in test:\n",
    "        hist=histogram(cluster_model,des_img,K)\n",
    "        X_test.append(hist)\n",
    "    X_test=np.array(X_test)\n",
    "    X_test=X_test.reshape(len(X_test),K)\n",
    "    Y_train=np.array(Y_train)\n",
    "    Y_val=np.array(Y_val)\n",
    "    Y_test=np.array(Y_test)\n",
    "    \n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test, cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_svm(X_train, X_test, Y_train,Y_test,c_vals, gamma_vals,cv):\n",
    "    param_grid = [{'C': c_vals, 'gamma': gamma_vals, 'kernel': ['rbf']}]\n",
    "    svc = GridSearchCV(SVC(), param_grid,cv=cv, n_jobs=-1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    test_score = svc.score(X_test, Y_test)\n",
    "    print 'test score :', test_score\n",
    "    return svc, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svc_rbf(X_train,Y_train,skf,c,gam):\n",
    "    svc=SVC(C=c, kernel='rbf',gamma= gam)\n",
    "    print \"SVM model initiated\"\n",
    "    score=[]\n",
    "    for train,test in skf.split(X_train,Y_train):\n",
    "        x=X_train[train]\n",
    "        y=Y_train[train]\n",
    "        svc.fit(x,y)\n",
    "        scr_iter=svc.score(X_train[test],Y_train[test])\n",
    "        score.append(scr_iter)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vbov_grid():\n",
    "    # initialising global variables\n",
    "    path_data=\"/home/atrij/artificial_intelligence/CK+/Emotion\"\n",
    "    path_image=\"/home/atrij/artificial_intelligence/CK+/cohn-kanade-images\"\n",
    "    filename_des='img_des'\n",
    "    filename_label='img_label'\n",
    "    percent_test=0.1\n",
    "    percent_val=0\n",
    "    cv=10\n",
    "    # checking for descriptor and label file in directory, if not present creating file\n",
    "    if (os.path.exists(filename_des) & os.path.exists(filename_label))==0:\n",
    "        ld= labeled_data(path_data,path_image)\n",
    "        save_descriptor_label(filename_des,filename_label,ld)\n",
    "    \n",
    "    # load descriptors from img_des\n",
    "    fileObject = open(filename_des,'r')  \n",
    "    des = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "      \n",
    "    # load labels from img_des\n",
    "    fileObject = open(filename_label,'r')\n",
    "    Y = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    #scores = ['precision', 'recall']\n",
    "    # retrieving image feature vectors using K-means clustering\n",
    "    #cv = StratifiedKFold(n_splits=k_split)\n",
    "    K=[200,225,250,275,300,325,350,375,400,425,450,475,500,525,550,575,600]\n",
    "    c_vals=[1, 5, 10, 100]\n",
    "    gamma_vals=[0.1, 0.01, 0.0001, 0.00001]\n",
    "    for k in K:\n",
    "        X_train, Y_train,_,_, X_test, Y_test,_= cluster_split(des,Y, k, percent_test, percent_val)\n",
    "        svc, test_score = run_svm(X_train, X_test, Y_train,Y_test,c_vals,gamma_vals,cv)\n",
    "        print svc.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60031 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=200, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 200 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.535714285714\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60144 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=225, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 225 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.5\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60502 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=250, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 250 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.607142857143\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60207 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=275, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 275 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.571428571429\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59852 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=300, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 300 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.571428571429\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60189 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=325, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 325 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=325. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.607142857143\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59470 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=350, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 350 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.535714285714\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60293 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=375, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 375 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=375. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.535714285714\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60426 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=400, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 400 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.5\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60346 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=425, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 425 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=425. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.607142857143\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60110 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=450, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 450 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=450. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.678571428571\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60253 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=475, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 475 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=475. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.714285714286\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60462 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=500, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 500 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.642857142857\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60047 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=525, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 525 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=525. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.571428571429\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59787 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=550, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 550 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=550. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.5\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60209 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=575, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 575 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=575. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.571428571429\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59902 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=600, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 600 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atrij/.virtualenvs/cv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1381: RuntimeWarning: init_size=300 should be larger than k=600. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "test score : 0.678571428571\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "vbov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vbov_indi():\n",
    "    # initialising global variables\n",
    "    path_data=\"/home/atrij/artificial_intelligence/CK+/Emotion\"\n",
    "    path_image=\"/home/atrij/artificial_intelligence/CK+/cohn-kanade-images\"\n",
    "    filename_des='img_des'\n",
    "    filename_label='img_label'\n",
    "    percent_test=0.1\n",
    "    percent_val=0\n",
    "    cv=10\n",
    "    # checking for descriptor and label file in directory, if not present creating file\n",
    "    if (os.path.exists(filename_des) & os.path.exists(filename_label))==0:\n",
    "        ld= labeled_data(path_data,path_image)\n",
    "        save_descriptor_label(filename_des,filename_label,ld)\n",
    "    \n",
    "    # load descriptors from img_des\n",
    "    fileObject = open(filename_des,'r')  \n",
    "    des = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "      \n",
    "    # load labels from img_des\n",
    "    fileObject = open(filename_label,'r')\n",
    "    Y = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    #scores = ['precision', 'recall']\n",
    "    # retrieving image feature vectors using K-means clustering\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    K=[200,225,250,275,300,325,350,375,400,425,450,475,500,525,550,575,600]\n",
    "    c_vals=[1, 5, 10, 100]\n",
    "    gamma_vals=[0.1, 0.01, 0.0001, 0.00001]\n",
    "     \n",
    "    for k in K:\n",
    "        X_train, Y_train,_,_, X_test, Y_test,_= cluster_split(des,Y, k, percent_test, percent_val)\n",
    "        for c in c_vals:\n",
    "            for gam in gamma_vals:\n",
    "                score = svc_rbf(X_train,Y_train,skf,c,gam)\n",
    "                avg=np.array(score).mean()\n",
    "                print 'C:',c, 'gamma:',gam,'cv_score:', avg,'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60510 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=200, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 200 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.397317556027 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.425820992097 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.50255270241 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.425820992097 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.575112427529 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.25190465474 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.425820992097 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.535222372789 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.575590324781 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60578 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=225, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 225 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.408495651719 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.424111592143 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.494647117395 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.424111592143 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.568652166656 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.424111592143 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.55605430361 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.575130745549 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60112 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=250, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 250 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.420336532271 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.427266042427 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.500898855289 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.427266042427 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.573282663365 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.427266042427 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.575576952728 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.580016670099 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60016 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=275, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 275 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.408311406157 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.441951785265 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.525041610334 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.441951785265 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.597607427821 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.441951785265 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.553423302895 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.601055703683 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59980 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=300, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 300 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.407274539798 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.410364767248 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.527284181838 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.410364767248 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.580495635069 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.410364767248 \n",
      "\n",
      "SVM model initiated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 gamma: 0.0001 cv_score: 0.576831323646 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.591219043207 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59432 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=325, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 325 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.426018357141 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.447542548778 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.479921155325 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.447542548778 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.585532819998 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.447542548778 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.559506083981 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.59201139889 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60218 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=350, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 350 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.413424272418 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.436909334919 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.450065752416 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.436909334919 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.584882629022 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.436909334919 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.543717849832 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.58165682257 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59634 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=375, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 375 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.416214161758 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.449257247196 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.49055133913 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.449257247196 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.563631416095 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.449257247196 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.56896220157 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.570740247088 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59967 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=400, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 400 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.393574460042 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.431959840599 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.489091374575 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.431959840599 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.56654159647 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.431959840599 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.537572074144 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.566673871603 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60325 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=425, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 425 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.422619222294 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.431232234133 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.498078142955 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.431232234133 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.588054329607 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 gamma: 0.01 cv_score: 0.431232234133 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.63047429565 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.588054329607 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59983 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=450, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 450 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.4230512824 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.454071336403 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.472198848079 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.454071336403 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.601899755194 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.454071336403 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.593915608288 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.595298023593 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59700 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=475, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 475 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.445401681982 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.4587940629 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.475276671269 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.4587940629 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.58785706449 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.4587940629 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.573224600567 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.591428493061 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59815 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=500, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 500 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.454702656222 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.491203139945 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.454610225794 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.491203139945 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.611390341128 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.491203139945 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.643690211897 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.621483497164 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60454 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=525, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 525 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.390124422484 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.444388098494 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.451134983943 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.444388098494 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.572708378753 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.444388098494 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.644776018631 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.579186957645 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59781 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=550, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 550 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.431277518142 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.454105362553 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.447275169098 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.454105362553 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.580946566332 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.454105362553 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.589922450593 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.584517994904 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "60427 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=575, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 575 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.429490469012 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.444669424606 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.462221465141 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.444669424606 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.588089423475 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.444669424606 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.588207651461 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.598467209493 \n",
      "\n",
      "\n",
      " total size of data: 326\n",
      "\n",
      " size of training data: 298 \n",
      " size of validation data: 0 \n",
      " size of test data: 28\n",
      "59803 descriptors before clustering\n",
      "Using clustering model MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=10,\n",
      "        n_clusters=600, n_init=3, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)...\n",
      "Clustering on training set to get codebook of 600 words\n",
      "done clustering.\n",
      "\n",
      " calculting histogram vectors of training set\n",
      "\n",
      " calculting histogram vectors of validation set\n",
      "\n",
      " calculting histogram vectors of test set\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.01 cv_score: 0.440158977378 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 0.0001 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 1 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.01 cv_score: 0.486594443735 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 0.0001 cv_score: 0.48148856446 \n",
      "\n",
      "SVM model initiated\n",
      "C: 5 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.01 cv_score: 0.486594443735 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 0.0001 cv_score: 0.595610335571 \n",
      "\n",
      "SVM model initiated\n",
      "C: 10 gamma: 1e-05 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.1 cv_score: 0.248874351709 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.01 cv_score: 0.486594443735 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 0.0001 cv_score: 0.619148736786 \n",
      "\n",
      "SVM model initiated\n",
      "C: 100 gamma: 1e-05 cv_score: 0.598640638602 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vbov_indi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
